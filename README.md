# ğŸ“ˆ OtimizaÃ§Ã£o de HiperparÃ¢metros com GridSearchCV

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Data Science](https://img.shields.io/badge/Data%20Science-Optimization-blue?style=for-the-badge)

## ğŸ“– DescriÃ§Ã£o
Este repositÃ³rio Ã© dedicado ao **Fine-tuning** de modelos de Machine Learning para classificaÃ§Ã£o de sentimentos. AtravÃ©s da tÃ©cnica de **GridSearchCV**, explorei o espaÃ§o de parÃ¢metros de diversos algoritmos para encontrar a configuraÃ§Ã£o Ã³tima, garantindo a mÃ¡xima performance preditiva.

## ğŸš€ Como funciona o GridSearchCV
O `GridSearchCV` realiza uma busca exaustiva sobre uma grade de parÃ¢metros especificada, combinada com **ValidaÃ§Ã£o Cruzada (Cross-Validation)**. 

### Exemplo PrÃ¡tico: Support Vector Classifier (SVC)
Para o modelo SVC, definimos diferentes valores para os parÃ¢metros `C`, `gamma` e `kernel`:

```python
# DefiniÃ§Ã£o do Grid de ParÃ¢metros
parameters = {
    'C': [1, 10, 100, 1000],
    'gamma': [1, 0.1, 0.001, 0.0001],
    'kernel': ['linear', 'rbf']
}

# Pipeline integrando VetorizaÃ§Ã£o e Modelo
modelo = Pipeline(steps=[
    ('vectorizer', TfidfVectorizer()),
    ('modelo', SVC())
])

# InstanciaÃ§Ã£o do GridSearchCV
clf = GridSearchCV(modelo, parameters, refit='accuracy', verbose=3)
```

## ğŸ§® A MatemÃ¡tica do Treinamento

O nÃºmero total de treinamentos Ã© o produto das combinaÃ§Ãµes de parÃ¢metros pelo nÃºmero de folds da validaÃ§Ã£o cruzada:

**4 (C) x 4 (gamma) x 2 (kernel) x 5 (folds) = 160 fits**

## ğŸ“Š Resultados e Rankeamento

O processo gera um ranking detalhado. No caso do SVC, o modelo vencedor utilizou:

**AcurÃ¡cia**: 0.7895

**ParÃ¢metros**: `{'C': 10, 'gamma': 1, 'kernel': 'rbf'}`

| Rank | ParÃ¢metros (C, gamma, kernel)                     | Score (Mean Test) |
|:-----|:--------------------------------------------------|------------------:|
| 1Âº   | {'C': 10, 'gamma': 1, 'kernel': 'rbf'}            |            0.7895 |
| 2Âº   | {'C': 1000, 'gamma': 1, 'kernel': 'rbf'}          |            0.7890 |
| 3Âº   | {'C': 100, 'gamma': 1, 'kernel': 'rbf'}           |            0.7890 |

## ğŸ“‚ Modelos Otimizados neste Projeto

Acesse os notebooks especÃ­ficos para cada implementaÃ§Ã£o:

[ğŸ”¥ Gradient Boosting](https://github.com/alan-vieira/an_sent_ajuste_hiperparametros/blob/main/gradient_boosting_tfidf_oversampling.ipynb)

[ğŸŒ² Random Forest](https://github.com/alan-vieira/an_sent_ajuste_hiperparametros/blob/main/random_forest_tfidf_oversampling.ipynb)

[ğŸ¤– XGBoost](https://github.com/alan-vieira/an_sent_ajuste_hiperparametros/blob/main/xgb_tfidf_oversampling.ipynb)

[ğŸ“ˆ Logistic Regression](https://github.com/alan-vieira/an_sent_ajuste_hiperparametros/blob/main/logistic_regression_tfidf_oversampling.ipynb)

[ğŸ§  MLP (Rede Neural)](https://github.com/alan-vieira/an_sent_ajuste_hiperparametros/blob/main/mlp_tfidf_oversampling.ipynb)

[ğŸ‘‰ Veja todos os 10 modelos no repositÃ³rio](https://github.com/alan-vieira/an_sent_ajuste_hiperparametros)

## ğŸ› ï¸ Ferramentas

`Python` â€¢ `Scikit-Learn` â€¢ `Pandas` â€¢ `Spacy` â€¢ `Simplemma` â€¢ `Matplotlib` â€¢ `Seaborn`

## ğŸ‘¤ Autor

**Alan Vieira** - *Engenheiro de TelecomunicaÃ§Ãµes & Especialista em Dados*

- [LinkedIn](https://www.linkedin.com/in/alansilvavieira)

- [GitHub PortfÃ³lio](https://github.com/alan-vieira)





